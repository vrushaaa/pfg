import json
from huggingface_hub import InferenceClient
import time

class PersonalizedGenerator:
    def __init__(self, model_name="google/gemma-2-2b-it", token=None):
        # Initialize the Hugging Face Inference API client
        print(f"Initializing Inference API client for {model_name}...")
        self.client = InferenceClient(model=model_name, token=token)
        print("Inference API client initialized successfully")
    
    def prepare_user_history(self, db, speaker_id, current_utt_id):
        """
        Prepare user history for the LLM.
        
        Args:
            db: Database instance.
            speaker_id (str): Speaker ID.
            current_utt_id (str): Current utterance ID.
        
        Returns:
            dict: Structured user history for the LLM.
        """
        history = db.get_speaker_history(speaker_id)
        analysis_history = db.get_speaker_analysis_history(speaker_id)
        
        if not history or len(analysis_history) < 2:
            return {"error": f"Not enough history for speaker {speaker_id}. Need at least 2 attempts for trends."}
        
        user_history = {
            "speaker_id": speaker_id,
            "total_attempts": len(history),
            "attempts": [],
            "phoneme_issues": {}
        }
        
        for i, (utt, analysis_entry) in enumerate(zip(history, analysis_history)):
            score_entry = utt["scores"]
            attempt = {
                "utt_id": utt["utt_id"],
                "scores": {
                    "accuracy": score_entry["accuracy"],
                    "fluency": score_entry["fluency"],
                    "prosodic": score_entry["prosodic"]
                },
                "analysis_feedback": analysis_entry if analysis_entry else "Not available"
            }
            user_history["attempts"].append(attempt)
            
            for w in score_entry["word_scores"]:
                for i, score in enumerate(w["phones-accuracy"]):
                    if score < 1.5:
                        phone = w["phones"][i]
                        user_history["phoneme_issues"][phone] = user_history["phoneme_issues"].get(phone, 0) + 1
                if "mispronunciations" in w and w["mispronunciations"]:
                    for mis in w["mispronunciations"]:
                        phone = mis["canonical-phone"]
                        user_history["phoneme_issues"][phone] = user_history["phoneme_issues"].get(phone, 0) + 1
        
        user_history["attempts"].sort(key=lambda x: x["utt_id"])
        return user_history
    
    def generate_personalized(self, db, speaker_id, current_utt_id):
        """
        Generate personalized feedback using the Hugging Face Inference API.
        
        Args:
            db: Database instance.
            speaker_id (str): Speaker ID.
            current_utt_id (str): Current utterance ID.
        
        Returns:
            str: Personalized feedback generated by the API.
        """
        # Prepare the user history
        user_history = self.prepare_user_history(db, speaker_id, current_utt_id)
        
        if "error" in user_history:
            return user_history["error"]
        
        # Create a prompt for the LLM
        prompt = self._create_prompt(user_history)
        
        # Use the Inference API to generate feedback with retry logic
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = self.client.text_generation(
                    prompt,
                    max_new_tokens=300,  # Increased to allow for longer responses
                    temperature=0.7,
                    top_p=0.9,
                    do_sample=True
                )
                
                # Extract the feedback part (remove the prompt if it's included in the output)
                feedback = response.strip()
                if feedback.startswith(prompt):
                    feedback = feedback[len(prompt):].strip()
                
                return feedback
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"API call failed (attempt {attempt + 1}/{max_retries}): {str(e)}. Retrying in 5 seconds...")
                    time.sleep(5)
                else:
                    return f"Error generating feedback via API after {max_retries} attempts: {str(e)}"
    
    def _create_prompt(self, user_history):
        """
        Create a prompt for the LLM based on the user's history.
        
        Args:
            user_history (dict): Structured user history.
        
        Returns:
            str: The prompt for the LLM.
        """
        speaker_id = user_history["speaker_id"]
        total_attempts = user_history["total_attempts"]
        
        # Summarize scores and trends
        accuracy_scores = [attempt["scores"]["accuracy"] for attempt in user_history["attempts"]]
        fluency_scores = [attempt["scores"]["fluency"] for attempt in user_history["attempts"]]
        prosodic_scores = [attempt["scores"]["prosodic"] for attempt in user_history["attempts"]]
        
        avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)
        avg_fluency = sum(fluency_scores) / len(fluency_scores)
        avg_prosodic = sum(prosodic_scores) / len(prosodic_scores)
        
        # Identify phoneme issues
        phoneme_issues = user_history["phoneme_issues"]
        top_phonemes = sorted(phoneme_issues.items(), key=lambda x: x[1], reverse=True)[:3]  # Top 3 phoneme issues
        
        # Create the prompt
        prompt = (
            f"You are a language coach providing personalized feedback to a non-native English speaker (Speaker ID: {speaker_id}). "
            f"They have made {total_attempts} attempts to speak English sentences. Here is a summary of their performance:\n"
            f"- Average Accuracy: {avg_accuracy:.1f}/10 (pronunciation correctness)\n"
            f"- Average Fluency: {avg_fluency:.1f}/10 (smoothness of speech)\n"
            f"- Average Prosodic: {avg_prosodic:.1f}/10 (intonation and rhythm)\n"
            f"They struggle with the following phonemes (with frequency of issues):\n"
        )
        
        for phoneme, count in top_phonemes:
            prompt += f"- '{phoneme}': {count} times\n"
        
        prompt += (
            "\nBased on this information, provide concise, encouraging feedback (3-4 sentences) to help the speaker improve. "
            "Focus on their strengths to build their confidence, highlight specific areas for improvement, and offer practical, actionable tips for practicing the phonemes they struggle with (e.g., specific exercises, tongue placement, or example words). "
            "Suggest using online resources like Forvo (https://forvo.com) to listen to native pronunciations or YouGlish (https://youglish.com) to hear words in context. "
            "Keep the tone positive, supportive, and confident in their ability to improve, as if speaking to a motivated learner. "
            "Do not repeat the numerical scores in the feedback."
        )
        
        return prompt